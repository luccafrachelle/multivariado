---
title: "Entrega Final - Multivariado"
author: "Lucca Frachelle, Joaquín Silva, Cecilia Waksman"
format: pdf
editor: visual
---

# Resumen Ejecutivo

Los datos utilizados en este análisis surgen de un estudio epidemiológico llevado a cabo en la Facultad de Odontología de la Universidad de la República, Uruguay, durante el período 2015-2016. Los mismos son recogidos de 602 individuos que acudieron a consulta. Este análisis se centra mayormente en el uso de variables binarias para identificar la presencia de enfermedades no transmisibles (ENT) y otros factores de riesgo asociados con la salud bucal, tratados aquí como comorbilidades. Los atributos estudiados se agrupan en tres bloques principales: comportamentales, ENT generales, y patologías odontológicas específicas, además se cuenta con variables demográficas diversas (edad, ingreso, sexo, nivel educativo). Entre los comportamentales se incluyen el consumo diario de tabaco, el consumo nocivo de alcohol y la insuficiencia de actividad física. Los ENT se refieren a condiciones como sobrepeso/obesidad, razón de cintura-cadera, hipertensión y diabetes. Finalmente, las condiciones odontológicas incluyen la prevalencia de bolsas periodontales, pérdida dentaria, caries y prevalencia de patología periapical infecciosa (PIP).

![](./variables.png)

Además contamos con las variables C, P, O y CPO, donde C es la cantidad de dientes con caries, P es la cantidad de dientes perdidos debido a caries y O la cantidad de dientes con caries obturadas, además CPO es la suma de las tres anteriores.

El estudio empleó técnicas de muestreo sistemático para seleccionar una muestra representativa, ajustada para medir prevalencias de hasta un 25% con un margen de error de 0.05 y un nivel de confianza del 95%. Se aplicaron cuestionarios sociodemográficos y exámenes bucodentales completos, evaluando la salud dental y de la mucosa, además de medidas antropométricas y análisis de presión arterial y glucemia.

# Introducción

En el presente trabajo, aprovechamos un conjunto de datos derivados de individuos que solicitaron atención en la Facultad de Odontología de la Universidad de la República, Uruguay, entre 2015 y 2016, para realizar un estudio exploratorio que indaga cómo los factores de riesgo comportamentales y las enfermedades no transmisibles (ENT) influyen en las patologías odontológicas. A través del uso de métodos de clasificación tanto supervisada, Análisis de Discriminantes, como no supervisada, Clustering, buscamos comprender las interacciones y posibles correlaciones entre estos distintos aspectos de la salud.

Este trabajo se centra en analizar las asociaciones entre variables, con el fin de identificar patrones que sugieran cómo los hábitos de vida y las condiciones de salud impactan en la salud bucal.

Así, nuestro análisis no solo ayuda a esclarecer la estructura de los datos y la relación entre diversas condiciones de salud, sino que también facilita el entendimiento de los factores de riesgo que afectan en la salud bucal.

# Marco metodológico

Completar...

## Clustering

Este es un método de clasificación no supervisada que, aplicado a una base de datos, consiste en dividir la misma en subgrupos/clusters de observaciones mediante un orden determinado. Dicho orden toma en cuenta cierta distancia (a definir, depende del tipo de clustering a usar y de la estructura de los datos) entre subgrupos y/o observaciones, según los valores que tomen las variables de dicha base.

**Clusters jerárquicos:**

Los clusters de tipo jerárquico se entienden como particiones encajadas que deben seguir cierta jerarquía basada para la aglomeración o separación de los subconjuntos. Gracias a ello los mismos permiten seguir claramente la historia de construcción de cada grupo.
Existen dos tipos de clusters jerárquicos:

- **Divisivos**: Comienza tomando como grupo a todo el conjunto de individuos, los cuales irá separando en subgrupos en las siguientes etapas hasta obtener tantos clusters como observaciones.

- **Agregativo**: Cada individuo comienza siendo un cluster unitario que se une con otros en las etapas siguientes hasta formarse un único cluster que cuenta con todos los individuos.

En nuestro análisis usaremos únicamente los de tipo agregativo.

En este tipo de clustering, la distancia a utilizar es seleccionada según las características de las variables en cuestión, así como también la relación entre las mismas. En nuestro caso, como contamos con variables tanto numéricas como categóricas, es necesario usar la distancia de Gower.

La **distancia de Gower** se calcula de distinta manera según el tipo de variable, pero siempre los valores obtenidos se encuentran entre 0 y 1, lo que permite que estas distancias sean comparables.

... completar

**Clusters no jerárquicos:**

Para el análisis usaremos unicamente los clusters no jerárquicos por el método de **K-means**. Este consiste en seleccionas K centros provisorios, los cuales inducen una partición del conjunto de individuos en k subgrupos. Luego, se vuelven a seleccionar nuevos centros de gravedad, en base a las distancias de los individuos del grupo a los centros. Esta nueva partición cuenta con una reducción de la variabilidad intragrupo. Este proceso se repite siempre y cuando las particiones en etapas sucesivas sean diferentes o hasta que se alcanza un número de iteraciones determinado.

**Análisis de Discriminante**

completar...

```{r}
#| output: false
library(tidyverse)
library(cluster)
library(NbClust)
library(factoextra)
```

\newpage

# Carga de datos y limpieza

```{r}
load('./data/bfm.RData')
```

Originalmente se cargan 4 dataframes : D, datos , DATOS y dato01.601, de los cuales solo utilizaremos datos.

```{r}
datos = datos %>% select(-c(17:22 , 28)) %>% filter(!if_any(c(1:23), is.na))
datos = datos %>% select(-c(16, 22, 23))
```

# Clasificasión no supervisada

## Cluster Jerárquico

```{r}
DG<-(daisy(datos,metric = "gower"))
fviz_dist(DG, lab_size = 8)
#str(DG)

```

```{r}
W.DG<-agnes(DG,diss=TRUE,method = "ward")
fviz_dend(W.DG)
```

```{r}
#no funciona
#NbClust(datos, diss=DG, distance = "NULL" , method = "single", index="pseudot2")
```

```{r}
#tampoco funciona
# source('indicadores.R')            
# IND<-indicadores(W.DG$merge , datos,10)
```


## Cluster No Jerárquico

```{r}
df_dummy <- model.matrix(~ . - 1, data = datos)

df_scaled <- scale(df_dummy)
```

```{r}
fviz_nbclust(df_scaled, kmeans, method = "wss") +
  labs(subtitle = "Codo")
```

```{r}
fviz_nbclust(df_scaled, kmeans, method = "silhouette") +
  labs(subtitle = "Silueta")
```


Dada la información obtenida de los gráficos de codo y silueta, se procede a realizar un análisis de cluster con 5 grupos. Ya que el gráfico de codo no presenta un punto de inflexión claro se opta por un punto medio entre silueta y codo.

```{r}
kmeans5 <- kmeans(df_scaled, 5, iter.max = 10000)
datos = datos %>% mutate(cluster = kmeans5$cluster)
```

### Análisis entre clusters

```{r}
datos %>% ggplot() + geom_bar(aes(x = cluster, fill = factor(cluster))) + labs(title = "Distribución de clusters")
```

```{r}
## cluster por niveledrec
datos %>% ggplot() + geom_bar(aes(x = cluster, fill = factor(cluster))) + facet_wrap(~niveledu) + labs(title = "Distribución de clusters por nivel educativo")
```

Se observa como el cluster 2 capta en su mayoría las personas que tuvieron educación hasta bachillerato , completo o icompleto. El cluster 5 capta las personas que tienen ciclo basicos completos o incompletos.

```{r}
### por ingreso
datos %>% ggplot() + geom_bar(aes(x = cluster, fill = factor(cluster))) + facet_wrap(~ingresos) + labs(title = "Distribución de clusters por ingresos")


```

Pareceria que el ingreso no esta explicando la variabilidad de los clusters.

```{r}
## edad
datos %>% ggplot() + geom_boxplot(aes(x = cluster, y = edad, fill = factor(cluster))) + labs(title = "Edad por cluster")


```

Aunque el cluster 4 pareceria no estar siendo explicado por las otras variables , es explicado por la edad. Este cluster tiene una edad mediana de 70 años. Siendo con diferencia el cluster con mayor edad.

De igual forma el cluster número 3 tiene una edad mediana cercana 60 años. Estando bastante concentrada respecto a esta variable.

```{r}
### respecto a cpo y edad
datos %>% ggplot() + geom_point(aes(x = edad, y = CPO, color = factor(cluster))) + labs(title = "Edad vs CPO por cluster")
```

Se observa que el cluster 4 es el que tiene mayor CPO y mayor edad.De cierta forma explicando lo que se veia en el PCA de la entrega anterior. La edad y CPO estan relacionados de manera positiva. Se observa como los cluster que estan captados por edades mas avanzadas son los que tienen mayor CPO.

Aunque durante el analisis se pudo entender la mayoria de cluster , el cluster 1 no se pudo explicar de manera clara. Asi que se va a realizar un analisis respecto a las variables odontologicas.

Con un poco de detalle se puede ver que el cluster 1 2 y 5 tienen un correlación lineal entre ellos 3.

Por otro lado el cluster 4 y 3 no estan correlacionados per se comportan parecido. Con la unica diferencia que el cluster 3 tiene un mayor edad.

```{r}
datos %>% ggplot() + geom_bar(aes(x = cluster, fill = factor(cluster))) + facet_wrap(~V8) + labs(title = "Distribución de clusters por prevalencia de bolsa")
```

```{r}
datos %>% ggplot() + geom_bar(aes(x = cluster, fill = factor(cluster))) + facet_wrap(~V9) + labs(title = "Distribución de clusters por perdida dentaria")
```

Es impresionante como todo el cluster 2 queda limpio en pérdida dentaria. A su vez se empieza a entender mejor al cluster 1 . La mayoria de ellos no tienen perdida dentaria.

```{r}
datos %>% ggplot() + geom_bar(aes(x = cluster, fill = factor(cluster))) + facet_wrap(~V9) + labs(title = "Distribución de clusters por perdida dentaria")

```

La mayorian de los individuos del cluster 1 no tienen perdida dentaria.

# Análisis supervisado

## Análisis de discriminante logistico

Teniendo en cuenta que la prevalencia de pip(V11) es un factor importante de riesgo odnologico se procede a realizar un analisis de discriminante logistico. Para intentar predecir la prevalencia de pip en base a las otras variables.

```{r}
library(caret)
library(pROC)
trainIndex <- createDataPartition(datos$V11, p = 0.7, list = FALSE)
trainData <- datos[trainIndex, ]
testData <- datos[-trainIndex, ]
```

```{r}
modelo_logistico <- glm(V11 ~ ., data = trainData, family = binomial)
```

el summary es re largo

```{r}
predicciones <- predict(modelo_logistico, newdata = testData, type = "response")
roc_obj <- roc(testData$V11, predicciones)
plot(roc_obj, col = "blue")

```

```{r}
best_threshold <- coords(roc_obj, "best", ret = "threshold")
best_threshold = as.numeric(best_threshold)
best_threshold

```

```{r}

predicciones <- predict(modelo_logistico, newdata = testData, type = "response")

predicciones_clase <- ifelse(predicciones > best_threshold, 1, 0)
predicciones_clase <- ifelse(predicciones_clase == 1, "si", "no") %>% factor(levels = c("si", "no"))


conf_matrix <- confusionMatrix(predicciones_clase, testData$V11)
conf_matrix

```
